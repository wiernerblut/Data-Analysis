{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465098c-3246-4be2-98a2-63c885410acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/maksym/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "0    cited\n",
      "1    cited\n",
      "2    cited\n",
      "3    cited\n",
      "4    cited\n",
      "Name: case_outcome, dtype: object\n",
      "info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24985 entries, 0 to 24984\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   case_outcome     24985 non-null  object \n",
      " 1   case_text        24985 non-null  object \n",
      " 2   outcome_numeric  14667 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 585.7+ KB\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 01:42:17.271846: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 19988000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 107s 168ms/step - loss: nan - accuracy: 0.4866\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 90s 144ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 83s 133ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 83s 132ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 81s 130ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 80s 128ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 83s 133ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 59s 95ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 9/10\n",
      "474/625 [=====================>........] - ETA: 14s - loss: nan - accuracy: 0.4874"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.src.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPool2D, Embedding, LSTM\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "df = pd.read_csv('legal_text_classification.csv', sep=',', usecols=[\"case_outcome\", \"case_text\"])\n",
    "outcome_mapping = {'cited': 0, 'applied': 1}\n",
    "\n",
    "# Create a new column 'outcome_numeric' based on the mapping\n",
    "df['outcome_numeric'] = df['case_outcome'].map(outcome_mapping)\n",
    "#df.head() \n",
    "\n",
    "\n",
    "def clean_the_text(text):\n",
    "  stop_words = stopwords.words(\"english\")\n",
    "  text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "  text = text.lower()\n",
    "  text = ' '.join([word for word in text.split(' ') if word not in stop_words])\n",
    "  #print(text)\n",
    "  return text\n",
    "df['case_text'] = df['case_text'].apply(lambda x: str(x) if isinstance(x, (str, float)) else '').apply(clean_the_text)\n",
    "#df['case_outcome'] = df['case_outcome'].apply(lambda x: str(x) if isinstance(x, (str, float)) else '').apply(clean_the_text)\n",
    "\n",
    "\n",
    "X = df['case_text']\n",
    "y = df['outcome_numeric']\n",
    "#y = y.astype(float)\n",
    "print(\"head\")\n",
    "print(df['case_outcome'][0:5])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12345)\n",
    "\n",
    "print(\"info\")\n",
    "df.info()\n",
    "\n",
    "token = Tokenizer(lower=False)\n",
    "token.fit_on_texts(X_train)\n",
    "X_train = token.texts_to_sequences(X_train)\n",
    "X_test = token.texts_to_sequences(X_test)\n",
    "\n",
    "array = []\n",
    "for i_train in X_train:\n",
    "    array.append(len(i_train))\n",
    "maximum_len = int(np.ceil(np.mean(array))) \n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maximum_len)\n",
    "X_test = pad_sequences(X_test, maxlen=maximum_len)\n",
    "total_words = len(token.word_index) + 1\n",
    "model_task3 = keras.Sequential()\n",
    "model_task3.add(Embedding(total_words, 32, input_length= maximum_len))\n",
    "model_task3.add(LSTM(10, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_task3.add(Dense(1, activation='sigmoid'))\n",
    "model_task3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_task3.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "\n",
    "results = model_task3.evaluate(X_test, y_test, verbose=0)\n",
    "print('Losses are : ', results[0])\n",
    "print('Accuracy is : ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7efff5e-40de-4890-a3a0-8e1469365fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cdb540-df36-4805-85de-f8521036b157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
