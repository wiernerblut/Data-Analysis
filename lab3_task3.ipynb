{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8465098c-3246-4be2-98a2-63c885410acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/maksym/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "0    cited\n",
      "1    cited\n",
      "2    cited\n",
      "3    cited\n",
      "4    cited\n",
      "Name: case_outcome, dtype: object\n",
      "info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24985 entries, 0 to 24984\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   case_outcome     24985 non-null  object \n",
      " 1   case_text        24985 non-null  object \n",
      " 2   outcome_numeric  14667 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 585.7+ KB\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 60s 93ms/step - loss: nan - accuracy: 0.4866\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 50s 80ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 50s 81ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 56s 90ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 58s 93ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 59s 94ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 56s 89ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 52s 84ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 52s 84ms/step - loss: nan - accuracy: 0.4868\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 52s 83ms/step - loss: nan - accuracy: 0.4868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fe2ac109f90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.src.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPool2D, Embedding, LSTM\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "df = pd.read_csv('legal_text_classification.csv', sep=',', usecols=[\"case_outcome\", \"case_text\"])\n",
    "outcome_mapping = {'cited': 0, 'applied': 1}\n",
    "\n",
    "# Create a new column 'outcome_numeric' based on the mapping\n",
    "df['outcome_numeric'] = df['case_outcome'].map(outcome_mapping)\n",
    "#df.head() \n",
    "\n",
    "\n",
    "def clean_the_text(text):\n",
    "  stop_words = stopwords.words(\"english\")\n",
    "  text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "  text = text.lower()\n",
    "  text = ' '.join([word for word in text.split(' ') if word not in stop_words])\n",
    "  #print(text)\n",
    "  return text\n",
    "df['case_text'] = df['case_text'].apply(lambda x: str(x) if isinstance(x, (str, float)) else '').apply(clean_the_text)\n",
    "#df['case_outcome'] = df['case_outcome'].apply(lambda x: str(x) if isinstance(x, (str, float)) else '').apply(clean_the_text)\n",
    "\n",
    "\n",
    "X = df['case_text']\n",
    "y = df['outcome_numeric']\n",
    "#y = y.astype(float)\n",
    "print(\"head\")\n",
    "print(df['case_outcome'][0:5])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12345)\n",
    "\n",
    "print(\"info\")\n",
    "df.info()\n",
    "\n",
    "token = Tokenizer(lower=False)\n",
    "token.fit_on_texts(X_train)\n",
    "X_train = token.texts_to_sequences(X_train)\n",
    "X_test = token.texts_to_sequences(X_test)\n",
    "\n",
    "array = []\n",
    "for i_train in X_train:\n",
    "    array.append(len(i_train))\n",
    "maximum_len = int(np.ceil(np.mean(array))) \n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maximum_len)\n",
    "X_test = pad_sequences(X_test, maxlen=maximum_len)\n",
    "total_words = len(token.word_index) + 1\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(total_words, 32, input_length= maxlen))\n",
    "model.add(LSTM(10, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7efff5e-40de-4890-a3a0-8e1469365fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
